---
title: Empathy in Multi-Agent Reinforcement Learning
type: Research
status: Completed
date: 2025-12-21
authors:
  - name: Christina Eirini Christodoulou
    avatar: /assets/img/team/christina_christodoulou.png
  - name: Simone De Giorgi
    avatar: /assets/img/team/simone_degiorgi.jpg
  - name: Lavinia Maria Alexandra Skandali
    avatar: /assets/img/team/lavinia_skandali.jpg
---

This paper studies whether valuing other agents’ rewards can improve outcomes in multi-agent reinforcement learning. We model empathy as a reward-weighting parameter and compare fixed empathy with empathy that is learned over time using a bandit-based adaptation mechanism.

We evaluate this setup in the Prisoner’s Dilemma, the Stag Hunt, and a Renewable Resource Sharing environment. In all three settings, higher empathy clearly improves cooperation, welfare, and long-run stability. Yet when agents adapt empathy autonomously, they stabilize at intermediate levels instead of reaching the welfare-maximizing one. 

Read the full paper to see how this gap emerges and why the adaptation mechanism becomes the key constraint!

[Full Paper](/assets/reports/Empathy_MARL.pdf)
