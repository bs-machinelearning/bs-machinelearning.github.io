---
title: "Deep Learning Ensemble for Automated Pallet Counting: A Multi-Target Regression Approach with Explainable AI"
date: 2025-11-07
type: Research
cover: /assets/img/proj/cnn_pallet_cover.jpg
authors:
  - name: "Simone De Giorgi"
    avatar: "/assets/img/team/simone_degiorgi.jpg"
    link: "https://www.linkedin.com/in/simone-de-giorgi/"
    desc: "MSc in Economics at Bocconi University"

buttons:
  - name: "Report"
    link: "https://bsmachinelearning.com/assets/reports/Paper_pallet_bsml.pdf"
  - name: "Code"
    link: "https://github.com/Simo-dg/cnn-pallet-counting"
---


Pallet counting in warehouses demands accuracy and speed under heavy occlusions and lighting variability. We present a **multi-target regression** approach that predicts CHEP and EPAL counts in a single forward pass and derives total pallets via a logical constraint $\hat{y}_\mathrm{total}=\hat{y}_\mathrm{CHEP}+\hat{y}_\mathrm{EPAL}$.

**Backbones & training.** We fine-tune three CNNs: EfficientNet-B3, ResNet-50, ConvNeXt-Tiny, with an AdamW + one-cycle schedule on $224{\times}224$ inputs. Augmentations include resized crops, flips, affine transforms, color jitter, blur, JPEG noise, coarse dropout, and ImageNet normalization. Loss is SmoothL1 over total/CHEP/EPAL (total from the sum of the predicted types).

**Ensemble.** Final predictions are the mean of the three models, leveraging architectural diversity. Grad-CAM provides heatmaps for interpretability (edges, stack boundaries, CHEP color cues).

**Dataset & split.** 130 proprietary warehouse images, 80/20 train/validation split.

**Results (validation set).**  
- Total pallets: Ensemble MAE 1.151, RMSE 1.634, $R^2=0.875$ (best single: EfficientNet-B3 MAE 1.401).  
- CHEP: Ensemble MAE 0.918, RMSE 1.457, $R^2=0.945$ (ConvNeXt-Tiny lowest MAE 0.721).  
- EPAL: Ensemble MAE 0.857, RMSE 1.295, $R^2=0.950$ (EfficientNet-B3 best single MAE 1.009).

**Takeaways.** Different backbones specialize on different pallet types; the ensemble captures complementary cues and improves overall accuracy while remaining efficient for near real-time use.